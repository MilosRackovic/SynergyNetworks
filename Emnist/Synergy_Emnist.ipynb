{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr73brpWhHxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09f0241-8105-4bab-91b1-6b0e47f2e7cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchattacks in /usr/local/lib/python3.7/dist-packages (3.3.0)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "from torchvision import datasets, transforms\n",
        "import pickle\n",
        "!pip install torchattacks==3.3.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Konstante za ponovne treninge (da bude uvek isto)"
      ],
      "metadata": {
        "id": "_qwVweGuif1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "lGW5pcPrhgwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Konfiguracija modela"
      ],
      "metadata": {
        "id": "cAgYgASrip4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OMEGA = 1\n",
        "HIDDEN = 500\n",
        "CONV_OUT = 4 * 4 * 50\n",
        "NUM_CLASSES = 47\n",
        "\n",
        "LR = 0.01\n",
        "MOM = 0.5"
      ],
      "metadata": {
        "id": "bWnyOLYDhUw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glavna klasa modela"
      ],
      "metadata": {
        "id": "gnnoqsWdisbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import ToTensor\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, net_type):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.net_type = net_type\n",
        "\n",
        "        if ('normal' in self.net_type) or ('hybrid_nor' in self.net_type) or ('synergy_nor' in self.net_type) or ('synergy_all' in self.net_type):\n",
        "           self.conv1_normal = nn.Conv2d(1, 20, 5, 1)\n",
        "           self.pool_normal = nn.MaxPool2d(2, 2)\n",
        "           self.conv2_normal = nn.Conv2d(20, 50, 5, 1)\n",
        "\n",
        "        if ('negative' in self.net_type) or ('hybrid_neg' in self.net_type) or ('synergy_neg' in self.net_type) or ('synergy_all' in self.net_type):\n",
        "           self.conv1_negative = nn.Conv2d(1, 20, 5, 1)\n",
        "           self.pool_negative = nn.MaxPool2d(2, 2)\n",
        "           self.conv2_negative = nn.Conv2d(20, 50, 5, 1)\n",
        "\n",
        "        if ('normal' in self.net_type) or ('synergy_nor' in self.net_type) or ('synergy_all' in self.net_type):\n",
        "           self.fc1_normal = nn.Linear(CONV_OUT, HIDDEN)\n",
        "           self.fc2_normal = nn.Linear(HIDDEN, NUM_CLASSES)\n",
        "\n",
        "        if ('hybrid_nor' in self.net_type) or ('synergy_nor' in self.net_type) or ('synergy_all' in self.net_type):\n",
        "           self.fc1_normal_n = nn.Linear(CONV_OUT, HIDDEN)\n",
        "           self.fc2_normal_n = nn.Linear(HIDDEN, NUM_CLASSES)\n",
        "\n",
        "        if ('hybrid_neg' in self.net_type) or ('synergy_neg' in self.net_type) or ('synergy_all' in self.net_type):\n",
        "           self.fc1_negative = nn.Linear(CONV_OUT, HIDDEN)\n",
        "           self.fc2_negative = nn.Linear(HIDDEN, NUM_CLASSES)\n",
        "\n",
        "        if ('negative' in self.net_type) or ('synergy_neg' in self.net_type) or ('synergy_all' in self.net_type):\n",
        "           self.fc1_negative_n = nn.Linear(CONV_OUT, HIDDEN)\n",
        "           self.fc2_negative_n = nn.Linear(HIDDEN, NUM_CLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # conv block:\n",
        "        if ('normal' in self.net_type) or ('hybrid_nor' in self.net_type) or ('synergy_nor' in self.net_type) or ('synergy_all' in self.net_type):\n",
        "           x_normal = self.pool_normal(F.relu(self.conv1_normal(x)))\n",
        "           x_normal = self.pool_normal(F.relu(self.conv2_normal(x_normal)))\n",
        "           x_normal = x_normal.view(-1, CONV_OUT)\n",
        "\n",
        "        if ('negative' in self.net_type) or ('hybrid_neg' in self.net_type) or ('synergy_neg' in self.net_type) or ('synergy_all' in self.net_type):\n",
        "           x_negative = self.pool_negative(F.relu(self.conv1_negative(x)))\n",
        "           x_negative = self.pool_negative(F.relu(self.conv2_negative(x_negative)))\n",
        "           x_negative = x_negative.view(-1, CONV_OUT)\n",
        "\n",
        "        # fc block:\n",
        "        if 'synergy_nor' in self.net_type:\n",
        "            x_normal_normal = self.fc2_normal(F.relu(self.fc1_normal(x_normal)))\n",
        "            x_normal_negative = self.fc2_normal_n(F.relu(self.fc1_normal_n(1 - x_normal)))\n",
        "\n",
        "            o = x_normal_normal + x_normal_negative * OMEGA\n",
        "\n",
        "        else:\n",
        "            if 'synergy_neg' in self.net_type:\n",
        "                x_negative_normal = self.fc2_negative(F.relu(self.fc1_negative(x_negative)))\n",
        "                x_negative_negative = self.fc2_negative_n(F.relu(self.fc1_negative_n(1 - x_negative)))\n",
        "\n",
        "                o = x_negative_normal + x_negative_negative * OMEGA\n",
        "\n",
        "            else:\n",
        "                if 'synergy_all' in self.net_type:\n",
        "                    x_normal_normal = self.fc2_normal(F.relu(self.fc1_normal(x_normal)))\n",
        "                    x_normal_negative = self.fc2_normal_n(F.relu(self.fc1_normal_n(1 - x_normal)))\n",
        "                    x_negative_normal = self.fc2_negative(F.relu(self.fc1_negative(x_negative)))\n",
        "                    x_negative_negative = self.fc2_negative_n(F.relu(self.fc1_negative_n(1 - x_negative)))\n",
        "\n",
        "                    o = x_normal_normal + x_normal_negative * OMEGA + x_negative_normal + x_negative_negative * OMEGA\n",
        "                else:\n",
        "                    if 'negative' in self.net_type:\n",
        "                         x = 1 - x_negative\n",
        "                         o = self.fc2_negative_n(F.relu(self.fc1_negative_n(x)))\n",
        "                    else:\n",
        "                         if 'normal' in self.net_type:\n",
        "                             x = x_normal\n",
        "                             o = self.fc2_normal(F.relu(self.fc1_normal(x)))\n",
        "                         else:\n",
        "                             if 'hybrid_neg' in self.net_type:\n",
        "                                 x = x_negative\n",
        "                                 o = self.fc2_negative(F.relu(self.fc1_negative(x)))\n",
        "                             else:\n",
        "                                 x = 1 - x_normal\n",
        "                                 o = self.fc2_normal_n(F.relu(self.fc1_normal_n(x)))\n",
        "\n",
        "        return F.log_softmax(o, dim=1)"
      ],
      "metadata": {
        "id": "cm71He_DhThk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pomoćne funkcije za trening i testove"
      ],
      "metadata": {
        "id": "nn5Sv1oliuJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, loss_fn=F.nll_loss):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 1000 == 0:\n",
        "            print('[{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'\n",
        "                  .format(model.net_type, epoch, batch_idx * len(data),\n",
        "                          len(train_loader.dataset),\n",
        "                          100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, loss_fn=F.nll_loss, dataset_name=None, filter_map=None):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    index_store = []\n",
        "    with torch.no_grad():\n",
        "        for i, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            if filter_map and dataset_name in filter_map:\n",
        "              for batch in data:\n",
        "                for channel in batch:\n",
        "                  channel.mul_(filter_map[dataset_name].to(device))\n",
        "            output = model(data)\n",
        "            test_loss += loss_fn(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            c = pred.eq(target.view_as(pred)).sum().item()\n",
        "            correct += c\n",
        "            index_store.append((i, c))\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('[{}] Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'\n",
        "          .format(model.net_type, test_loss, correct, len(test_loader.dataset),\n",
        "                  100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    return index_store"
      ],
      "metadata": {
        "id": "PdVhO8PahqJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Učitavanje podataka (i \"stari\" filteri)"
      ],
      "metadata": {
        "id": "cixC7Xj9iy4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {'num_workers': 2, 'pin_memory': True} \\\n",
        "         if torch.cuda.is_available() else {}\n",
        "\n",
        "f_v, f_h, f_d, f_t = torch.ones((28, 28)), torch.ones((28, 28)), \\\n",
        "                     torch.ones((28, 28)), torch.ones((28, 28))\n",
        "f_v[:, :14] = 0  # vertical filter\n",
        "f_h[:14, :] = 0  # horizontal filter\n",
        "f_d[:14, 15:], f_d[15:, :14] = 0, 0  # diagonal filter\n",
        "f_t[6:15, 6:15], f_t[18:27, 11:20], f_t[8:17, 17:26] = 0, 0, 0  # tcut\n",
        "\n",
        "\n",
        "def mnist_loader(train=False):\n",
        "    return torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', download=True, train=train,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=64 if train else 1, shuffle=train, **kwargs)\n",
        "\n",
        "\n",
        "def emnist_loader(split='balanced', batch_size=64):\n",
        "    def _loader(train=False, batch_size=64):\n",
        "        return torch.utils.data.DataLoader(\n",
        "           datasets.EMNIST('../data', split=split, download=True, train=train,\n",
        "                           transform=transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.1307,), (0.3081,))\n",
        "                            ])), batch_size=batch_size, shuffle=train, **kwargs)\n",
        "    return _loader\n",
        "\n",
        "transform_cifar = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def cifar10_loader(train=False, batch_size=4):\n",
        "    return torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10('../data', download=True, train=train,\n",
        "                          transform=transform_cifar),\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=train, **kwargs)\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "def cifar10_loader_resnet(train=False, batch_size=1536):\n",
        "    return torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10('../data', download=True, train=train,\n",
        "                          transform=transform_train if train else transform_test),\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=train, **kwargs)\n",
        "\n",
        "cifar10_classes = ['plane', 'car', 'bird', 'cat',\n",
        "                   'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "hCCYyEi2h0f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gde se radi trening (GPU)"
      ],
      "metadata": {
        "id": "Wi8tBpyyjFwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "PIJioPFwjDya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trening modela"
      ],
      "metadata": {
        "id": "AyHSdFzCjRWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = emnist_loader()\n",
        "\n",
        "train_loader = loader(train=True)\n",
        "test_loader = loader()\n",
        "\n",
        "model_normal = Net('normal').to(device)\n",
        "model_negative = Net('negative').to(device)\n",
        "\n",
        "model_synergy_nor = Net('synergy_nor').to(device)\n",
        "model_synergy_neg = Net('synergy_neg').to(device)\n",
        "model_synergy_all = Net('synergy_all').to(device)\n",
        "\n",
        "model_hybrid_nor = Net('hybrid_nor').to(device)\n",
        "model_hybrid_neg = Net('hybrid_neg').to(device)\n",
        "\n",
        "model_tr_synergy_all = Net('tr_synergy_all').to(device)"
      ],
      "metadata": {
        "id": "IfyD9EzAhoxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obični model"
      ],
      "metadata": {
        "id": "YhaCBQgZjqPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Normal net:\n",
        "\n",
        "optimizer_normal = optim.SGD(filter(lambda p: p.requires_grad,\n",
        "                             model_normal.parameters()), lr=LR, momentum=MOM)\n",
        "\n",
        "for epoch in range(1, 10 + 1):\n",
        "    train(model_normal, device, train_loader, optimizer_normal,\n",
        "          epoch, loss_fn=F.cross_entropy)\n",
        "\n",
        "for param in model_normal.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "conv1_nor = model_normal.conv1_normal\n",
        "conv2_nor = model_normal.conv2_normal\n",
        "\n",
        "# Zamrzavanje slojeva\n",
        "conv1_nor.weight.requires_grad = False\n",
        "conv2_nor.weight.requires_grad = False\n",
        "conv1_nor.bias.requires_grad = False\n",
        "conv2_nor.bias.requires_grad = False\n",
        "\n"
      ],
      "metadata": {
        "id": "tVzPpwdVjnwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d65ce4-03c9-4af2-bacb-4510be28c941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[normal] Train Epoch: 1 [0/112800 (0%)]\tLoss: 3.850885\n",
            "[normal] Train Epoch: 1 [64000/112800 (57%)]\tLoss: 0.695619\n",
            "[normal] Train Epoch: 2 [0/112800 (0%)]\tLoss: 0.462280\n",
            "[normal] Train Epoch: 2 [64000/112800 (57%)]\tLoss: 0.496040\n",
            "[normal] Train Epoch: 3 [0/112800 (0%)]\tLoss: 0.297183\n",
            "[normal] Train Epoch: 3 [64000/112800 (57%)]\tLoss: 0.379306\n",
            "[normal] Train Epoch: 4 [0/112800 (0%)]\tLoss: 0.409661\n",
            "[normal] Train Epoch: 4 [64000/112800 (57%)]\tLoss: 0.316735\n",
            "[normal] Train Epoch: 5 [0/112800 (0%)]\tLoss: 0.468509\n",
            "[normal] Train Epoch: 5 [64000/112800 (57%)]\tLoss: 0.497590\n",
            "[normal] Train Epoch: 6 [0/112800 (0%)]\tLoss: 0.581184\n",
            "[normal] Train Epoch: 6 [64000/112800 (57%)]\tLoss: 0.308109\n",
            "[normal] Train Epoch: 7 [0/112800 (0%)]\tLoss: 0.298122\n",
            "[normal] Train Epoch: 7 [64000/112800 (57%)]\tLoss: 0.415047\n",
            "[normal] Train Epoch: 8 [0/112800 (0%)]\tLoss: 0.224063\n",
            "[normal] Train Epoch: 8 [64000/112800 (57%)]\tLoss: 0.224526\n",
            "[normal] Train Epoch: 9 [0/112800 (0%)]\tLoss: 0.225632\n",
            "[normal] Train Epoch: 9 [64000/112800 (57%)]\tLoss: 0.177341\n",
            "[normal] Train Epoch: 10 [0/112800 (0%)]\tLoss: 0.174707\n",
            "[normal] Train Epoch: 10 [64000/112800 (57%)]\tLoss: 0.244219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Snimanje modela"
      ],
      "metadata": {
        "id": "IeNrNmoGSQyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_normal.state_dict(), 'model_normal.pt')"
      ],
      "metadata": {
        "id": "QdJlwhO3SUJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Učitavanje modela"
      ],
      "metadata": {
        "id": "Y2NS-lhHSrEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_normal = Net('normal').to(device)\n",
        "model_normal.load_state_dict(torch.load('model_normal.pt'))\n",
        "# model_normal.load_state_dict(torch.load('model_normal.pt', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "tuFdgsMtSvNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf92f80-c92d-4263-c7a8-7c1a79397e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Štampanje težina"
      ],
      "metadata": {
        "id": "-PS8a1K9vZoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "   print(conv1_nor.weight)\n"
      ],
      "metadata": {
        "id": "RVQgEj_Uvd4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Negativni (hibrid) model"
      ],
      "metadata": {
        "id": "cMsSJFdbjr6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Hybrid net:\n",
        "\n",
        "# Deljenje zamrznutih slojeva\n",
        "model_hybrid_nor.conv1_normal = conv1_nor\n",
        "model_hybrid_nor.conv2_normal = conv2_nor\n",
        "\n",
        "optimizer_hybrid_nor = optim.SGD(filter(lambda p: p.requires_grad,\n",
        "                             model_hybrid_nor.parameters()), lr=LR, momentum=MOM)\n",
        "\n",
        "for epoch in range(1, 10 + 1):\n",
        "    train(model_hybrid_nor, device, train_loader, optimizer_hybrid_nor,\n",
        "          epoch, loss_fn=F.cross_entropy)\n",
        "\n",
        "for param in model_hybrid_nor.parameters():\n",
        "  param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "-tTyH-UejbDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727d7aad-d66f-4154-8237-e4e820fb41b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hybrid_nor] Train Epoch: 1 [0/112800 (0%)]\tLoss: 4.365130\n",
            "[hybrid_nor] Train Epoch: 1 [64000/112800 (57%)]\tLoss: 0.594000\n",
            "[hybrid_nor] Train Epoch: 2 [0/112800 (0%)]\tLoss: 0.556093\n",
            "[hybrid_nor] Train Epoch: 2 [64000/112800 (57%)]\tLoss: 0.262030\n",
            "[hybrid_nor] Train Epoch: 3 [0/112800 (0%)]\tLoss: 0.258823\n",
            "[hybrid_nor] Train Epoch: 3 [64000/112800 (57%)]\tLoss: 0.163162\n",
            "[hybrid_nor] Train Epoch: 4 [0/112800 (0%)]\tLoss: 0.420351\n",
            "[hybrid_nor] Train Epoch: 4 [64000/112800 (57%)]\tLoss: 0.305534\n",
            "[hybrid_nor] Train Epoch: 5 [0/112800 (0%)]\tLoss: 0.275575\n",
            "[hybrid_nor] Train Epoch: 5 [64000/112800 (57%)]\tLoss: 0.292623\n",
            "[hybrid_nor] Train Epoch: 6 [0/112800 (0%)]\tLoss: 0.282821\n",
            "[hybrid_nor] Train Epoch: 6 [64000/112800 (57%)]\tLoss: 0.376338\n",
            "[hybrid_nor] Train Epoch: 7 [0/112800 (0%)]\tLoss: 0.185545\n",
            "[hybrid_nor] Train Epoch: 7 [64000/112800 (57%)]\tLoss: 0.246094\n",
            "[hybrid_nor] Train Epoch: 8 [0/112800 (0%)]\tLoss: 0.193338\n",
            "[hybrid_nor] Train Epoch: 8 [64000/112800 (57%)]\tLoss: 0.137952\n",
            "[hybrid_nor] Train Epoch: 9 [0/112800 (0%)]\tLoss: 0.206463\n",
            "[hybrid_nor] Train Epoch: 9 [64000/112800 (57%)]\tLoss: 0.263177\n",
            "[hybrid_nor] Train Epoch: 10 [0/112800 (0%)]\tLoss: 0.146297\n",
            "[hybrid_nor] Train Epoch: 10 [64000/112800 (57%)]\tLoss: 0.170816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Snimanje modela"
      ],
      "metadata": {
        "id": "RxogxixOW5Lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_hybrid_nor.state_dict(), 'model_hybrid_nor.pt')"
      ],
      "metadata": {
        "id": "mzH35ZrrW8TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Učitavanje modela"
      ],
      "metadata": {
        "id": "YsHC6FtYXIkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_hybrid_nor = Net('hybrid_nor').to(device)\n",
        "model_hybrid_nor.load_state_dict(torch.load('model_hybrid_nor.pt'))\n",
        "# model_hybrid_nor.load_state_dict(torch.load('model_hybrid_nor.pt', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "gFo593ITXL_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17662920-d913-4c9a-b63a-288e54297447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skroz negativni model"
      ],
      "metadata": {
        "id": "QTlEJJWljtsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Negative net:\n",
        "\n",
        "optimizer_negative = optim.SGD(filter(lambda p: p.requires_grad,\n",
        "                             model_negative.parameters()), lr=LR, momentum=MOM)\n",
        "\n",
        "for epoch in range(1, 10 + 1):\n",
        "    train(model_negative, device, train_loader, optimizer_negative,\n",
        "          epoch, loss_fn=F.cross_entropy)\n",
        "\n",
        "for param in model_negative.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "conv1_neg = model_negative.conv1_negative\n",
        "conv2_neg = model_negative.conv2_negative\n",
        "\n",
        "conv1_neg.weight.requires_grad = False\n",
        "conv2_neg.weight.requires_grad = False\n",
        "conv1_neg.bias.requires_grad = False\n",
        "conv2_neg.bias.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrofy2FrjfUp",
        "outputId": "80c28cf0-578f-4292-bea5-c5030cef9501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[negative] Train Epoch: 1 [0/112800 (0%)]\tLoss: 3.838741\n",
            "[negative] Train Epoch: 1 [64000/112800 (57%)]\tLoss: 0.695061\n",
            "[negative] Train Epoch: 2 [0/112800 (0%)]\tLoss: 0.563996\n",
            "[negative] Train Epoch: 2 [64000/112800 (57%)]\tLoss: 0.413599\n",
            "[negative] Train Epoch: 3 [0/112800 (0%)]\tLoss: 0.459479\n",
            "[negative] Train Epoch: 3 [64000/112800 (57%)]\tLoss: 0.541164\n",
            "[negative] Train Epoch: 4 [0/112800 (0%)]\tLoss: 0.354509\n",
            "[negative] Train Epoch: 4 [64000/112800 (57%)]\tLoss: 0.280990\n",
            "[negative] Train Epoch: 5 [0/112800 (0%)]\tLoss: 0.188881\n",
            "[negative] Train Epoch: 5 [64000/112800 (57%)]\tLoss: 0.450622\n",
            "[negative] Train Epoch: 6 [0/112800 (0%)]\tLoss: 0.228978\n",
            "[negative] Train Epoch: 6 [64000/112800 (57%)]\tLoss: 0.287582\n",
            "[negative] Train Epoch: 7 [0/112800 (0%)]\tLoss: 0.215137\n",
            "[negative] Train Epoch: 7 [64000/112800 (57%)]\tLoss: 0.159629\n",
            "[negative] Train Epoch: 8 [0/112800 (0%)]\tLoss: 0.468343\n",
            "[negative] Train Epoch: 8 [64000/112800 (57%)]\tLoss: 0.119397\n",
            "[negative] Train Epoch: 9 [0/112800 (0%)]\tLoss: 0.135052\n",
            "[negative] Train Epoch: 9 [64000/112800 (57%)]\tLoss: 0.310384\n",
            "[negative] Train Epoch: 10 [0/112800 (0%)]\tLoss: 0.277634\n",
            "[negative] Train Epoch: 10 [64000/112800 (57%)]\tLoss: 0.291867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Snimanje modela"
      ],
      "metadata": {
        "id": "DgSJ8NFRXk2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_negative.state_dict(), 'model_negative.pt')"
      ],
      "metadata": {
        "id": "bzeceDqVXrF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Učitavanje modela"
      ],
      "metadata": {
        "id": "a_gt070HX3Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_negative = Net('negative').to(device)\n",
        "model_negative.load_state_dict(torch.load('model_negative.pt'))\n",
        "# model_negative.load_state_dict(torch.load('model_negative.pt', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "kImG0VHFX6e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b4ad19-626c-4804-9741-34ef2c9a53ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skroz negativni (hibrid) model"
      ],
      "metadata": {
        "id": "_WHzYGGokqJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Hybrid_neg net:\n",
        "\n",
        "model_hybrid_neg.conv1_negative = conv1_neg\n",
        "model_hybrid_neg.conv2_negative = conv2_neg\n",
        "\n",
        "optimizer_hybrid_neg = optim.SGD(filter(lambda p: p.requires_grad,\n",
        "                             model_hybrid_neg.parameters()), lr=LR, momentum=MOM)\n",
        "\n",
        "for epoch in range(1, 10 + 1):\n",
        "    train(model_hybrid_neg, device, train_loader, optimizer_hybrid_neg,\n",
        "          epoch, loss_fn=F.cross_entropy)\n",
        "\n",
        "for param in model_hybrid_neg.parameters():\n",
        "  param.requires_grad = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx1Wm5n4k6kM",
        "outputId": "e7f64b3d-3d11-4edb-fcf7-e0fe24140a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hybrid_neg] Train Epoch: 1 [0/112800 (0%)]\tLoss: 4.013987\n",
            "[hybrid_neg] Train Epoch: 1 [64000/112800 (57%)]\tLoss: 0.449314\n",
            "[hybrid_neg] Train Epoch: 2 [0/112800 (0%)]\tLoss: 0.459528\n",
            "[hybrid_neg] Train Epoch: 2 [64000/112800 (57%)]\tLoss: 0.451301\n",
            "[hybrid_neg] Train Epoch: 3 [0/112800 (0%)]\tLoss: 0.405234\n",
            "[hybrid_neg] Train Epoch: 3 [64000/112800 (57%)]\tLoss: 0.273954\n",
            "[hybrid_neg] Train Epoch: 4 [0/112800 (0%)]\tLoss: 0.281573\n",
            "[hybrid_neg] Train Epoch: 4 [64000/112800 (57%)]\tLoss: 0.344358\n",
            "[hybrid_neg] Train Epoch: 5 [0/112800 (0%)]\tLoss: 0.155168\n",
            "[hybrid_neg] Train Epoch: 5 [64000/112800 (57%)]\tLoss: 0.485289\n",
            "[hybrid_neg] Train Epoch: 6 [0/112800 (0%)]\tLoss: 0.412850\n",
            "[hybrid_neg] Train Epoch: 6 [64000/112800 (57%)]\tLoss: 0.209984\n",
            "[hybrid_neg] Train Epoch: 7 [0/112800 (0%)]\tLoss: 0.263619\n",
            "[hybrid_neg] Train Epoch: 7 [64000/112800 (57%)]\tLoss: 0.302772\n",
            "[hybrid_neg] Train Epoch: 8 [0/112800 (0%)]\tLoss: 0.222865\n",
            "[hybrid_neg] Train Epoch: 8 [64000/112800 (57%)]\tLoss: 0.343343\n",
            "[hybrid_neg] Train Epoch: 9 [0/112800 (0%)]\tLoss: 0.399392\n",
            "[hybrid_neg] Train Epoch: 9 [64000/112800 (57%)]\tLoss: 0.173024\n",
            "[hybrid_neg] Train Epoch: 10 [0/112800 (0%)]\tLoss: 0.382269\n",
            "[hybrid_neg] Train Epoch: 10 [64000/112800 (57%)]\tLoss: 0.322987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Snimanje modela"
      ],
      "metadata": {
        "id": "LJxfeU63YUhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_hybrid_neg.state_dict(), 'model_hybrid_neg.pt')"
      ],
      "metadata": {
        "id": "5dRSkCmOYXCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Učitavanje modela"
      ],
      "metadata": {
        "id": "w2JDjyxKYhem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_hybrid_neg = Net('hybrid_neg').to(device)\n",
        "model_hybrid_neg.load_state_dict(torch.load('model_hybrid_neg.pt'))\n",
        "# model_hybrid_neg.load_state_dict(torch.load('model_hybrid_neg.pt', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "UDD80FpMYj52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60009d97-fa74-4796-a7fa-d1ab8f2afd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sinergije, bez treninga"
      ],
      "metadata": {
        "id": "N0bHHE0Qjv4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- synergy_nor net (not trained):\n",
        "\n",
        "model_synergy_nor.conv1_normal = conv1_nor\n",
        "model_synergy_nor.conv2_normal = conv2_nor\n",
        "\n",
        "model_synergy_nor.fc1_normal = model_normal.fc1_normal\n",
        "model_synergy_nor.fc2_normal = model_normal.fc2_normal\n",
        "\n",
        "model_synergy_nor.fc1_normal_n = model_hybrid_nor.fc1_normal_n\n",
        "model_synergy_nor.fc2_normal_n = model_hybrid_nor.fc2_normal_n\n",
        "\n",
        "# ---- synergy_neg net (not trained):\n",
        "\n",
        "model_synergy_neg.conv1_negative = conv1_neg\n",
        "model_synergy_neg.conv2_negative = conv2_neg\n",
        "\n",
        "model_synergy_neg.fc1_negative = model_hybrid_neg.fc1_negative\n",
        "model_synergy_neg.fc2_negative = model_hybrid_neg.fc2_negative\n",
        "\n",
        "model_synergy_neg.fc1_negative_n = model_negative.fc1_negative_n\n",
        "model_synergy_neg.fc2_negative_n = model_negative.fc2_negative_n\n",
        "\n",
        "# ---- synergy_all net (not trained):\n",
        "\n",
        "model_synergy_all.conv1_normal = conv1_nor\n",
        "model_synergy_all.conv2_normal = conv2_nor\n",
        "model_synergy_all.conv1_negative = conv1_neg\n",
        "model_synergy_all.conv2_negative = conv2_neg\n",
        "\n",
        "model_synergy_all.fc1_normal = model_normal.fc1_normal\n",
        "model_synergy_all.fc2_normal = model_normal.fc2_normal\n",
        "\n",
        "model_synergy_all.fc1_normal_n = model_hybrid_nor.fc1_normal_n\n",
        "model_synergy_all.fc2_normal_n = model_hybrid_nor.fc2_normal_n\n",
        "\n",
        "model_synergy_all.fc1_negative = model_hybrid_neg.fc1_negative\n",
        "model_synergy_all.fc2_negative = model_hybrid_neg.fc2_negative\n",
        "\n",
        "model_synergy_all.fc1_negative_n = model_negative.fc1_negative_n\n",
        "model_synergy_all.fc2_negative_n = model_negative.fc2_negative_n\n"
      ],
      "metadata": {
        "id": "K3og876Sjjcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Snimanje modela"
      ],
      "metadata": {
        "id": "DDfGtdBOY7GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_synergy_nor.state_dict(), 'model_synergy_nor.pt')\n",
        "torch.save(model_synergy_neg.state_dict(), 'model_synergy_neg.pt')\n",
        "torch.save(model_synergy_all.state_dict(), 'model_synergy_all.pt')"
      ],
      "metadata": {
        "id": "IrRg0aSsY9Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Učitavanje modela"
      ],
      "metadata": {
        "id": "bfo0XLVzZuC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_synergy_nor = Net('synergy_nor').to(device)\n",
        "model_synergy_nor.load_state_dict(torch.load('model_synergy_nor.pt'))\n",
        "# model_synergy_nor.load_state_dict(torch.load('model_synergy_nor.pt', map_location=torch.device('cpu')))\n",
        "model_synergy_neg = Net('synergy_neg').to(device)\n",
        "model_synergy_neg.load_state_dict(torch.load('model_synergy_neg.pt'))\n",
        "# model_synergy_neg.load_state_dict(torch.load('model_synergy_neg.pt', map_location=torch.device('cpu')))\n",
        "model_synergy_all = Net('synergy_all').to(device)\n",
        "model_synergy_all.load_state_dict(torch.load('model_synergy_all.pt'))\n",
        "# model_synergy_all.load_state_dict(torch.load('model_synergy_all.pt', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "uCyUjBNFZwam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8c47c7-aa95-4e94-ded9-b0ce55ef4449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trenirana sinergija"
      ],
      "metadata": {
        "id": "rXPz0hd_LPHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Trained synergy_all TF:\n",
        "\n",
        "model_tr_synergy_all.conv1_normal = conv1_nor\n",
        "model_tr_synergy_all.conv2_normal = conv2_nor\n",
        "model_tr_synergy_all.conv1_negative = conv1_neg\n",
        "model_tr_synergy_all.conv2_negative = conv2_neg\n",
        "\n",
        "optimizer_tr_synergy_all = optim.SGD(filter(lambda p: p.requires_grad,\n",
        "                                    model_tr_synergy_all.parameters()),\n",
        "                                    lr=LR, momentum=MOM)\n",
        "\n",
        "for epoch in range(1, 10 + 1):\n",
        "    train(model_tr_synergy_all, device, train_loader,\n",
        "          optimizer_tr_synergy_all, epoch, loss_fn=F.cross_entropy)\n"
      ],
      "metadata": {
        "id": "EIJ586vwLSlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6071a5fd-e361-4d15-d9b1-58d8686d561d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tr_synergy_all] Train Epoch: 1 [0/112800 (0%)]\tLoss: 6.024405\n",
            "[tr_synergy_all] Train Epoch: 1 [64000/112800 (57%)]\tLoss: 0.256137\n",
            "[tr_synergy_all] Train Epoch: 2 [0/112800 (0%)]\tLoss: 0.387234\n",
            "[tr_synergy_all] Train Epoch: 2 [64000/112800 (57%)]\tLoss: 0.249035\n",
            "[tr_synergy_all] Train Epoch: 3 [0/112800 (0%)]\tLoss: 0.394568\n",
            "[tr_synergy_all] Train Epoch: 3 [64000/112800 (57%)]\tLoss: 0.308688\n",
            "[tr_synergy_all] Train Epoch: 4 [0/112800 (0%)]\tLoss: 0.325880\n",
            "[tr_synergy_all] Train Epoch: 4 [64000/112800 (57%)]\tLoss: 0.206799\n",
            "[tr_synergy_all] Train Epoch: 5 [0/112800 (0%)]\tLoss: 0.190261\n",
            "[tr_synergy_all] Train Epoch: 5 [64000/112800 (57%)]\tLoss: 0.299697\n",
            "[tr_synergy_all] Train Epoch: 6 [0/112800 (0%)]\tLoss: 0.160542\n",
            "[tr_synergy_all] Train Epoch: 6 [64000/112800 (57%)]\tLoss: 0.300768\n",
            "[tr_synergy_all] Train Epoch: 7 [0/112800 (0%)]\tLoss: 0.120248\n",
            "[tr_synergy_all] Train Epoch: 7 [64000/112800 (57%)]\tLoss: 0.205827\n",
            "[tr_synergy_all] Train Epoch: 8 [0/112800 (0%)]\tLoss: 0.254975\n",
            "[tr_synergy_all] Train Epoch: 8 [64000/112800 (57%)]\tLoss: 0.252444\n",
            "[tr_synergy_all] Train Epoch: 9 [0/112800 (0%)]\tLoss: 0.129610\n",
            "[tr_synergy_all] Train Epoch: 9 [64000/112800 (57%)]\tLoss: 0.191430\n",
            "[tr_synergy_all] Train Epoch: 10 [0/112800 (0%)]\tLoss: 0.232780\n",
            "[tr_synergy_all] Train Epoch: 10 [64000/112800 (57%)]\tLoss: 0.163916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Snimanje modela"
      ],
      "metadata": {
        "id": "GKfgQu4haEXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_tr_synergy_all.state_dict(), 'model_tr_synergy_all.pt')"
      ],
      "metadata": {
        "id": "WhhqBDC6aHoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Učitavanje modela"
      ],
      "metadata": {
        "id": "XVvtTAubaIRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_tr_synergy_all = Net('tr_synergy_all').to(device)\n",
        "model_tr_synergy_all.load_state_dict(torch.load('model_tr_synergy_all.pt'))\n",
        "# model_tr_synergy_all.load_state_dict(torch.load('model_tr_synergy_all.pt', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "d-aU-eNqaLH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22dcb8aa-c52b-4b54-80ab-0f8a870e500e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova sečenja"
      ],
      "metadata": {
        "id": "EthmWCpAj0QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "def corner_kernel(factor):\n",
        "    kernel = np.ones((28, 28))\n",
        "    limit = int(factor * kernel.shape[0]) * 2\n",
        "    f = (1 - np.tril(kernel[:limit, :limit]))\n",
        "    kernel[kernel.shape[0] - limit:limit + kernel.shape[0], :limit] = f\n",
        "    return torch.tensor(kernel)\n",
        "\n",
        "def single_square_kernel(start=5, size=9):\n",
        "    kernel = np.ones((28, 28))\n",
        "    kernel[start:start+size, start:start+size] = 0.\n",
        "    return torch.tensor(kernel)\n",
        "\n",
        "def single_square_kernel_random(start=5, size=9):\n",
        "    random_pos = random.randint(0, 27 - size)\n",
        "    kernel = np.ones((28, 28))\n",
        "    kernel[random_pos:random_pos + size, random_pos:random_pos + size] = 0.\n",
        "    return torch.tensor(kernel)\n",
        "\n",
        "def multiple_square_kernel(n_cuts=3, start=5, size=9):\n",
        "    size_triple = size // n_cuts\n",
        "    kernel = np.ones((28, 28))\n",
        "\n",
        "    beg = start\n",
        "    end = start + size_triple\n",
        "\n",
        "    for _ in range(n_cuts):\n",
        "\n",
        "        kernel[beg:end, beg:end] = 0.\n",
        "\n",
        "        beg = end + 5\n",
        "        end = beg + size_triple\n",
        "\n",
        "    return torch.tensor(kernel)\n",
        "\n",
        "def multiple_square_kernel_random(n_cuts = 2, start=0, size=18, sep = 5):\n",
        "    size_triple = size // n_cuts\n",
        "    kernel = np.ones((28, 28))\n",
        "\n",
        "    beg1 = start + random.randint(1, sep)\n",
        "    end1 = beg1 + size_triple\n",
        "\n",
        "    beg2 = start + random.randint(1, sep)\n",
        "    end2 = beg2 + size_triple\n",
        "\n",
        "    for _ in range(n_cuts):\n",
        "\n",
        "        kernel[beg1:end1, beg2:end2] = 0.\n",
        "\n",
        "        beg1 = end1 + random.randint(1, sep)\n",
        "        end1 = beg1 + size_triple\n",
        "\n",
        "        beg2 = end2 + random.randint(1, sep)\n",
        "        end2 = beg2 + size_triple\n",
        "\n",
        "    return torch.tensor(kernel)"
      ],
      "metadata": {
        "id": "FE6fnn25iDLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testiranje sa svim modelima i svim \"novim\" sečenjima"
      ],
      "metadata": {
        "id": "LJ2SMsKtj2oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "models = [model_normal, model_negative, model_hybrid_nor, model_hybrid_neg, model_synergy_nor, model_synergy_neg, model_synergy_all, model_tr_synergy_all]\n",
        "\n",
        "\n",
        "dataset_names = ['Normal', 'C1', 'C2', 'C3', 'SSK', 'SSKR', 'MSK', 'MSKR']\n",
        "\n",
        "alldatasets = []\n",
        "for _ in dataset_names:\n",
        "    alldatasets.append(loader())\n",
        "\n",
        "filters_map = {'C1': corner_kernel(0.1),\n",
        "               'C2': corner_kernel(0.2), 'C3': corner_kernel(0.3),\n",
        "               'SSK': single_square_kernel(), 'SSKR': single_square_kernel_random(), 'MSK': multiple_square_kernel(), 'MSKR': multiple_square_kernel_random()}\n",
        "\n",
        "for dataset, name in zip(alldatasets, dataset_names):\n",
        "    print('Testing -- ' + name)\n",
        "    fdir = '.'\n",
        "    for m in models:\n",
        "        index_store = test(m, device, dataset, loss_fn=F.cross_entropy, dataset_name=name, filter_map=filters_map)\n",
        "        file_name = f'{fdir}/{m.net_type}-{name}-{dt.now()}.pth'\n",
        "        with open(file_name, 'wb') as f:\n",
        "            pickle.dump(index_store, f)\n",
        "\n",
        "for m in models:\n",
        "    file_name = f'{m.net_type}-{dt.now()}.pth'\n",
        "    torch.save(m.state_dict(), file_name)"
      ],
      "metadata": {
        "id": "WHwKfEbUh9UR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e24abd-f125-4a5d-9d47-e1c7988441c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing -- Normal\n",
            "[normal] Test set: Average loss: 0.3730, Accuracy: 16407/18800 (87%)\n",
            "[negative] Test set: Average loss: 0.3602, Accuracy: 16485/18800 (88%)\n",
            "[hybrid_nor] Test set: Average loss: 0.3678, Accuracy: 16480/18800 (88%)\n",
            "[hybrid_neg] Test set: Average loss: 0.3656, Accuracy: 16450/18800 (88%)\n",
            "[synergy_nor] Test set: Average loss: 0.5036, Accuracy: 16593/18800 (88%)\n",
            "[synergy_neg] Test set: Average loss: 0.4854, Accuracy: 16590/18800 (88%)\n",
            "[synergy_all] Test set: Average loss: 0.8516, Accuracy: 16636/18800 (88%)\n",
            "[tr_synergy_all] Test set: Average loss: 0.3687, Accuracy: 16443/18800 (87%)\n",
            "Testing -- C1\n",
            "[normal] Test set: Average loss: 0.3730, Accuracy: 16407/18800 (87%)\n",
            "[negative] Test set: Average loss: 0.3602, Accuracy: 16485/18800 (88%)\n",
            "[hybrid_nor] Test set: Average loss: 0.3678, Accuracy: 16477/18800 (88%)\n",
            "[hybrid_neg] Test set: Average loss: 0.3656, Accuracy: 16448/18800 (87%)\n",
            "[synergy_nor] Test set: Average loss: 0.5036, Accuracy: 16594/18800 (88%)\n",
            "[synergy_neg] Test set: Average loss: 0.4854, Accuracy: 16589/18800 (88%)\n",
            "[synergy_all] Test set: Average loss: 0.8516, Accuracy: 16634/18800 (88%)\n",
            "[tr_synergy_all] Test set: Average loss: 0.3687, Accuracy: 16443/18800 (87%)\n",
            "Testing -- C2\n",
            "[normal] Test set: Average loss: 0.3760, Accuracy: 16389/18800 (87%)\n",
            "[negative] Test set: Average loss: 0.3634, Accuracy: 16456/18800 (88%)\n",
            "[hybrid_nor] Test set: Average loss: 0.3704, Accuracy: 16452/18800 (88%)\n",
            "[hybrid_neg] Test set: Average loss: 0.3691, Accuracy: 16447/18800 (87%)\n",
            "[synergy_nor] Test set: Average loss: 0.5062, Accuracy: 16574/18800 (88%)\n",
            "[synergy_neg] Test set: Average loss: 0.4891, Accuracy: 16581/18800 (88%)\n",
            "[synergy_all] Test set: Average loss: 0.8569, Accuracy: 16626/18800 (88%)\n",
            "[tr_synergy_all] Test set: Average loss: 0.3718, Accuracy: 16451/18800 (88%)\n",
            "Testing -- C3\n",
            "[normal] Test set: Average loss: 0.5443, Accuracy: 15412/18800 (82%)\n",
            "[negative] Test set: Average loss: 0.4855, Accuracy: 15707/18800 (84%)\n",
            "[hybrid_nor] Test set: Average loss: 0.5297, Accuracy: 15548/18800 (83%)\n",
            "[hybrid_neg] Test set: Average loss: 0.5184, Accuracy: 15517/18800 (83%)\n",
            "[synergy_nor] Test set: Average loss: 0.7349, Accuracy: 15706/18800 (84%)\n",
            "[synergy_neg] Test set: Average loss: 0.6614, Accuracy: 15796/18800 (84%)\n",
            "[synergy_all] Test set: Average loss: 1.1964, Accuracy: 15850/18800 (84%)\n",
            "[tr_synergy_all] Test set: Average loss: 0.5282, Accuracy: 15507/18800 (82%)\n",
            "Testing -- SSK\n",
            "[normal] Test set: Average loss: 1.1282, Accuracy: 12474/18800 (66%)\n",
            "[negative] Test set: Average loss: 0.9497, Accuracy: 13272/18800 (71%)\n",
            "[hybrid_nor] Test set: Average loss: 1.0149, Accuracy: 13155/18800 (70%)\n",
            "[hybrid_neg] Test set: Average loss: 0.9939, Accuracy: 13069/18800 (70%)\n",
            "[synergy_nor] Test set: Average loss: 1.5257, Accuracy: 13182/18800 (70%)\n",
            "[synergy_neg] Test set: Average loss: 1.3515, Accuracy: 13459/18800 (72%)\n",
            "[synergy_all] Test set: Average loss: 2.4646, Accuracy: 13547/18800 (72%)\n",
            "[tr_synergy_all] Test set: Average loss: 0.9937, Accuracy: 13251/18800 (70%)\n",
            "Testing -- SSKR\n",
            "[normal] Test set: Average loss: 1.3833, Accuracy: 11343/18800 (60%)\n",
            "[negative] Test set: Average loss: 1.2815, Accuracy: 11743/18800 (62%)\n",
            "[hybrid_nor] Test set: Average loss: 1.4133, Accuracy: 11379/18800 (61%)\n",
            "[hybrid_neg] Test set: Average loss: 1.2789, Accuracy: 11668/18800 (62%)\n",
            "[synergy_nor] Test set: Average loss: 2.0850, Accuracy: 11679/18800 (62%)\n",
            "[synergy_neg] Test set: Average loss: 1.8673, Accuracy: 11955/18800 (64%)\n",
            "[synergy_all] Test set: Average loss: 3.4701, Accuracy: 12014/18800 (64%)\n",
            "[tr_synergy_all] Test set: Average loss: 1.3753, Accuracy: 11444/18800 (61%)\n",
            "Testing -- MSK\n",
            "[normal] Test set: Average loss: 0.4208, Accuracy: 16163/18800 (86%)\n",
            "[negative] Test set: Average loss: 0.4320, Accuracy: 16082/18800 (86%)\n",
            "[hybrid_nor] Test set: Average loss: 0.4209, Accuracy: 16183/18800 (86%)\n",
            "[hybrid_neg] Test set: Average loss: 0.4424, Accuracy: 15977/18800 (85%)\n",
            "[synergy_nor] Test set: Average loss: 0.5387, Accuracy: 16380/18800 (87%)\n",
            "[synergy_neg] Test set: Average loss: 0.5452, Accuracy: 16256/18800 (86%)\n",
            "[synergy_all] Test set: Average loss: 0.8985, Accuracy: 16434/18800 (87%)\n",
            "[tr_synergy_all] Test set: Average loss: 0.4350, Accuracy: 16070/18800 (85%)\n",
            "Testing -- MSKR\n",
            "[normal] Test set: Average loss: 1.1521, Accuracy: 12407/18800 (66%)\n",
            "[negative] Test set: Average loss: 0.9657, Accuracy: 13172/18800 (70%)\n",
            "[hybrid_nor] Test set: Average loss: 1.2064, Accuracy: 12281/18800 (65%)\n",
            "[hybrid_neg] Test set: Average loss: 1.0302, Accuracy: 12873/18800 (68%)\n",
            "[synergy_nor] Test set: Average loss: 1.6859, Accuracy: 12684/18800 (67%)\n",
            "[synergy_neg] Test set: Average loss: 1.3263, Accuracy: 13442/18800 (72%)\n",
            "[synergy_all] Test set: Average loss: 2.5531, Accuracy: 13314/18800 (71%)\n",
            "[tr_synergy_all] Test set: Average loss: 1.1192, Accuracy: 12646/18800 (67%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dodatni pomoćni elementi za FGSM"
      ],
      "metadata": {
        "id": "CCzvIyDbF8cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader_fgsm = emnist_loader()\n",
        "\n",
        "test_loader_fgsm = loader_fgsm(batch_size=1)\n",
        "\n",
        "# FGSM attack code\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # get element-wise signs for gradient ascent\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "    # clip to [0,1]\n",
        "    # perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image\n",
        "\n",
        "def test_fgsm(model, device, test_loader, epsilon):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        data.requires_grad = True\n",
        "        output = model(data)\n",
        "        init_pred = output.max(1, keepdim=True)[1]\n",
        "\n",
        "        # breakpoint()\n",
        "        # If the initial prediction is wrong\n",
        "        # dont bother attacking, just move on\n",
        "        if init_pred.item() != target.item():\n",
        "            continue\n",
        "\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        data_grad = data.grad.data\n",
        "\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        final_pred = output.max(1, keepdim=True)[1]\n",
        "\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))\n",
        "        else:\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))\n",
        "\n",
        "    final_acc = correct / float(len(test_loader))\n",
        "    print(\n",
        "        \"Model: {}\\tEpsilon: {}\\tTest Accuracy = {} / {} = {}\".format(\n",
        "            model.net_type, epsilon, correct, len(test_loader), final_acc\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return final_acc, adv_examples"
      ],
      "metadata": {
        "id": "RxB7HZnKGPPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testiranje za FGSM"
      ],
      "metadata": {
        "id": "emGnFMQZHclp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing:\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "models_fgsm = [\n",
        "    model_normal,\n",
        "    model_negative,\n",
        "    model_hybrid_nor,\n",
        "    model_hybrid_neg,\n",
        "    model_synergy_nor,\n",
        "    model_synergy_neg,\n",
        "    model_synergy_all,\n",
        "    model_tr_synergy_all\n",
        "]\n",
        "\n",
        "epsilons = [0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
        "accuracies = []\n",
        "examples = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "    for model in models_fgsm:\n",
        "        acc, ex = test_fgsm(model, device, test_loader_fgsm, eps)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "print('--- Total time: %s seconds ---' % (time.time() - start_time))\n"
      ],
      "metadata": {
        "id": "Z2p4pVLNHg4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67fe490e-550b-4177-a129-c5fcfb3f2ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: normal\tEpsilon: 0\tTest Accuracy = 16312 / 18800 = 0.8676595744680851\n",
            "Model: negative\tEpsilon: 0\tTest Accuracy = 16419 / 18800 = 0.8733510638297872\n",
            "Model: hybrid_nor\tEpsilon: 0\tTest Accuracy = 16449 / 18800 = 0.8749468085106383\n",
            "Model: hybrid_neg\tEpsilon: 0\tTest Accuracy = 16459 / 18800 = 0.8754787234042554\n",
            "Model: synergy_nor\tEpsilon: 0\tTest Accuracy = 16504 / 18800 = 0.8778723404255319\n",
            "Model: synergy_neg\tEpsilon: 0\tTest Accuracy = 16591 / 18800 = 0.8825\n",
            "Model: synergy_all\tEpsilon: 0\tTest Accuracy = 16625 / 18800 = 0.8843085106382979\n",
            "Model: tr_synergy_all\tEpsilon: 0\tTest Accuracy = 16431 / 18800 = 0.8739893617021277\n",
            "Model: normal\tEpsilon: 0.01\tTest Accuracy = 16147 / 18800 = 0.8588829787234042\n",
            "Model: negative\tEpsilon: 0.01\tTest Accuracy = 16231 / 18800 = 0.8633510638297872\n",
            "Model: hybrid_nor\tEpsilon: 0.01\tTest Accuracy = 16272 / 18800 = 0.865531914893617\n",
            "Model: hybrid_neg\tEpsilon: 0.01\tTest Accuracy = 16263 / 18800 = 0.8650531914893617\n",
            "Model: synergy_nor\tEpsilon: 0.01\tTest Accuracy = 16367 / 18800 = 0.8705851063829787\n",
            "Model: synergy_neg\tEpsilon: 0.01\tTest Accuracy = 16408 / 18800 = 0.8727659574468085\n",
            "Model: synergy_all\tEpsilon: 0.01\tTest Accuracy = 16477 / 18800 = 0.876436170212766\n",
            "Model: tr_synergy_all\tEpsilon: 0.01\tTest Accuracy = 16221 / 18800 = 0.8628191489361702\n",
            "Model: normal\tEpsilon: 0.02\tTest Accuracy = 15969 / 18800 = 0.8494148936170213\n",
            "Model: negative\tEpsilon: 0.02\tTest Accuracy = 16053 / 18800 = 0.8538829787234042\n",
            "Model: hybrid_nor\tEpsilon: 0.02\tTest Accuracy = 16080 / 18800 = 0.8553191489361702\n",
            "Model: hybrid_neg\tEpsilon: 0.02\tTest Accuracy = 16059 / 18800 = 0.8542021276595745\n",
            "Model: synergy_nor\tEpsilon: 0.02\tTest Accuracy = 16210 / 18800 = 0.8622340425531915\n",
            "Model: synergy_neg\tEpsilon: 0.02\tTest Accuracy = 16241 / 18800 = 0.8638829787234042\n",
            "Model: synergy_all\tEpsilon: 0.02\tTest Accuracy = 16328 / 18800 = 0.8685106382978723\n",
            "Model: tr_synergy_all\tEpsilon: 0.02\tTest Accuracy = 16020 / 18800 = 0.8521276595744681\n",
            "Model: normal\tEpsilon: 0.03\tTest Accuracy = 15767 / 18800 = 0.8386702127659574\n",
            "Model: negative\tEpsilon: 0.03\tTest Accuracy = 15817 / 18800 = 0.8413297872340425\n",
            "Model: hybrid_nor\tEpsilon: 0.03\tTest Accuracy = 15869 / 18800 = 0.844095744680851\n",
            "Model: hybrid_neg\tEpsilon: 0.03\tTest Accuracy = 15883 / 18800 = 0.8448404255319149\n",
            "Model: synergy_nor\tEpsilon: 0.03\tTest Accuracy = 16031 / 18800 = 0.8527127659574468\n",
            "Model: synergy_neg\tEpsilon: 0.03\tTest Accuracy = 16070 / 18800 = 0.8547872340425532\n",
            "Model: synergy_all\tEpsilon: 0.03\tTest Accuracy = 16174 / 18800 = 0.8603191489361702\n",
            "Model: tr_synergy_all\tEpsilon: 0.03\tTest Accuracy = 15820 / 18800 = 0.8414893617021276\n",
            "Model: normal\tEpsilon: 0.04\tTest Accuracy = 15576 / 18800 = 0.8285106382978723\n",
            "Model: negative\tEpsilon: 0.04\tTest Accuracy = 15572 / 18800 = 0.8282978723404255\n",
            "Model: hybrid_nor\tEpsilon: 0.04\tTest Accuracy = 15695 / 18800 = 0.8348404255319148\n",
            "Model: hybrid_neg\tEpsilon: 0.04\tTest Accuracy = 15657 / 18800 = 0.8328191489361703\n",
            "Model: synergy_nor\tEpsilon: 0.04\tTest Accuracy = 15816 / 18800 = 0.8412765957446808\n",
            "Model: synergy_neg\tEpsilon: 0.04\tTest Accuracy = 15863 / 18800 = 0.8437765957446809\n",
            "Model: synergy_all\tEpsilon: 0.04\tTest Accuracy = 16010 / 18800 = 0.8515957446808511\n",
            "Model: tr_synergy_all\tEpsilon: 0.04\tTest Accuracy = 15619 / 18800 = 0.8307978723404256\n",
            "Model: normal\tEpsilon: 0.05\tTest Accuracy = 15349 / 18800 = 0.8164361702127659\n",
            "Model: negative\tEpsilon: 0.05\tTest Accuracy = 15343 / 18800 = 0.8161170212765958\n",
            "Model: hybrid_nor\tEpsilon: 0.05\tTest Accuracy = 15464 / 18800 = 0.8225531914893617\n",
            "Model: hybrid_neg\tEpsilon: 0.05\tTest Accuracy = 15428 / 18800 = 0.8206382978723404\n",
            "Model: synergy_nor\tEpsilon: 0.05\tTest Accuracy = 15628 / 18800 = 0.8312765957446808\n",
            "Model: synergy_neg\tEpsilon: 0.05\tTest Accuracy = 15658 / 18800 = 0.8328723404255319\n",
            "Model: synergy_all\tEpsilon: 0.05\tTest Accuracy = 15857 / 18800 = 0.8434574468085106\n",
            "Model: tr_synergy_all\tEpsilon: 0.05\tTest Accuracy = 15395 / 18800 = 0.8188829787234042\n",
            "--- Total time: 4194.953163146973 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Black-box PGD"
      ],
      "metadata": {
        "id": "JBD57xxpn5IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchattacks\n",
        "from torchattacks import PGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_att = datasets.EMNIST(root='../data', split='balanced', train=True,\n",
        "                      download=True, transform=transforms.ToTensor())\n",
        "test_att = datasets.EMNIST(root='../data', split='balanced', train=False,\n",
        "                     download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader_att = torch.utils.data.DataLoader(train_att,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader_att = torch.utils.data.DataLoader(test_att,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "transform_att = transforms.Normalize((0.1307,), (0.3081,))\n",
        "\n",
        "# loader_att = emnist_loader()\n",
        "\n",
        "# test_loader_att = loader_att(batch_size=batch_size)\n",
        "\n",
        "models_test = [\n",
        "    model_normal,\n",
        "    model_synergy_nor,\n",
        "    model_synergy_all,\n",
        "    model_tr_synergy_all\n",
        "]\n",
        "\n",
        "epsilons = [0.0, 0.01, 0.03, 0.05]\n",
        "\n",
        "\n",
        "for epsilon in epsilons:\n",
        "    print(\"=\" * 30)\n",
        "    print(\"epsilon =\", epsilon)\n",
        "    print(\"=\" * 30)\n",
        "\n",
        "    for attacked in models_test:\n",
        "        print('attacked: ', attacked.net_type)\n",
        "        pgd_attack = PGD(attacked, eps=epsilon, alpha=2/255, steps=40)\n",
        "#        pgd_attack.set_return_type('int')\n",
        "        pgd_attack.save(data_loader=test_loader_att, save_path=\"../data/emnist_pgd.pt\",\n",
        "                        verbose=False, save_type='int')\n",
        "\n",
        "        adv_dict = torch.load(\"../data/emnist_pgd.pt\")\n",
        "        adv_images = adv_dict['adv_inputs']\n",
        "        adv_labels = adv_dict['labels']\n",
        "\n",
        "        adv_images = transform_att(adv_images.float()/255)\n",
        "        adv_data = TensorDataset(adv_images, adv_labels)\n",
        "        adv_loader = DataLoader(adv_data, batch_size=128, shuffle=False)\n",
        "\n",
        "        for model in models_test:\n",
        "            model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for images, labels in adv_loader:\n",
        "                images = images.cuda()\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels.cuda()).sum()\n",
        "\n",
        "            print(model.net_type, 'acc: %.2f %%' % (100 * float(correct) / total), end='; ')\n",
        "        print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_X8U-bcn9iU",
        "outputId": "825ab707-5260-479c-c21d-a787eab79a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "epsilon = 0.0\n",
            "==============================\n",
            "attacked:  normal\n",
            "normal acc: 86.77 %; synergy_nor acc: 87.79 %; synergy_all acc: 88.43 %; tr_synergy_all acc: 87.40 %; \n",
            "\n",
            "attacked:  synergy_nor\n",
            "normal acc: 86.77 %; synergy_nor acc: 87.79 %; synergy_all acc: 88.43 %; tr_synergy_all acc: 87.40 %; \n",
            "\n",
            "attacked:  synergy_all\n",
            "normal acc: 86.77 %; synergy_nor acc: 87.79 %; synergy_all acc: 88.43 %; tr_synergy_all acc: 87.40 %; \n",
            "\n",
            "attacked:  tr_synergy_all\n",
            "normal acc: 86.77 %; synergy_nor acc: 87.79 %; synergy_all acc: 88.43 %; tr_synergy_all acc: 87.40 %; \n",
            "\n",
            "==============================\n",
            "epsilon = 0.01\n",
            "==============================\n",
            "attacked:  normal\n",
            "normal acc: 85.19 %; synergy_nor acc: 86.55 %; synergy_all acc: 87.29 %; tr_synergy_all acc: 86.12 %; \n",
            "\n",
            "attacked:  synergy_nor\n",
            "normal acc: 84.99 %; synergy_nor acc: 86.12 %; synergy_all acc: 86.90 %; tr_synergy_all acc: 85.66 %; \n",
            "\n",
            "attacked:  synergy_all\n",
            "normal acc: 85.11 %; synergy_nor acc: 86.14 %; synergy_all acc: 86.67 %; tr_synergy_all acc: 85.45 %; \n",
            "\n",
            "attacked:  tr_synergy_all\n",
            "normal acc: 85.52 %; synergy_nor acc: 86.61 %; synergy_all acc: 87.12 %; tr_synergy_all acc: 85.32 %; \n",
            "\n",
            "==============================\n",
            "epsilon = 0.03\n",
            "==============================\n",
            "attacked:  normal\n",
            "normal acc: 81.07 %; synergy_nor acc: 83.31 %; synergy_all acc: 84.89 %; tr_synergy_all acc: 83.61 %; \n",
            "\n",
            "attacked:  synergy_nor\n",
            "normal acc: 80.41 %; synergy_nor acc: 81.68 %; synergy_all acc: 83.56 %; tr_synergy_all acc: 82.12 %; \n",
            "\n",
            "attacked:  synergy_all\n",
            "normal acc: 80.57 %; synergy_nor acc: 81.94 %; synergy_all acc: 82.66 %; tr_synergy_all acc: 81.19 %; \n",
            "\n",
            "attacked:  tr_synergy_all\n",
            "normal acc: 82.36 %; synergy_nor acc: 83.52 %; synergy_all acc: 84.27 %; tr_synergy_all acc: 80.98 %; \n",
            "\n",
            "==============================\n",
            "epsilon = 0.05\n",
            "==============================\n",
            "attacked:  normal\n",
            "normal acc: 76.21 %; synergy_nor acc: 79.20 %; synergy_all acc: 81.62 %; tr_synergy_all acc: 80.49 %; \n",
            "\n",
            "attacked:  synergy_nor\n",
            "normal acc: 75.07 %; synergy_nor acc: 76.03 %; synergy_all acc: 78.99 %; tr_synergy_all acc: 77.76 %; \n",
            "\n",
            "attacked:  synergy_all\n",
            "normal acc: 75.54 %; synergy_nor acc: 76.27 %; synergy_all acc: 76.81 %; tr_synergy_all acc: 75.79 %; \n",
            "\n",
            "attacked:  tr_synergy_all\n",
            "normal acc: 78.79 %; synergy_nor acc: 79.91 %; synergy_all acc: 80.51 %; tr_synergy_all acc: 75.44 %; \n",
            "\n"
          ]
        }
      ]
    }
  ]
}